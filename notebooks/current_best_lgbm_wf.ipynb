{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def transform_features2(df):\n",
    "    if 'MW' in df.columns:\n",
    "        df['MW_log'] = np.log1p(df['MW'])  # log(1+x) to avoid log(0)\n",
    "        df.drop(columns=['MW'], inplace=True)\n",
    "    \n",
    "    if \"NumOfConfUsed\" in df.columns:\n",
    "        df['NumOfConfUsed_log'] = np.log1p(df['NumOfConfUsed'])\n",
    "        df['NumOfConfUsed_binned'] = pd.cut(df['NumOfConfUsed'], bins=[0, 10, 20, 30, 40], labels=[1, 2, 3, 4])\n",
    "        df.drop(columns=['NumOfConfUsed'], inplace=True)\n",
    "    \n",
    "    if 'NumOfAtoms' in df.columns:\n",
    "        df['NumOfAtoms_sqrt'] = np.sqrt(df['NumOfAtoms'])\n",
    "        df['ConfUsed_to_Atoms'] = df['NumOfConfUsed_log'] / (df['NumOfAtoms'] + 1e-5)  # Avoid division by zero\n",
    "        df.drop(columns=['NumOfAtoms'], inplace=True)\n",
    "    \n",
    "    if 'NumOfN_binned' in df.columns:\n",
    "        df['NumOfN_binned'] = df['NumOfN_binned'].astype(int)  # Convert categories to integers\n",
    "\n",
    "    if 'NumOfConfUsed_binned' in df.columns:\n",
    "        df['NumOfConfUsed_binned'] = df['NumOfConfUsed_binned'].astype(int)  # Convert categories to integers\n",
    "        \n",
    "    df['Conf_to_ConfUsed_ratio'] = df['NumOfConf'] / df['NumOfConfUsed_binned']\n",
    "    df['MW_to_NumOfAtoms'] = df['MW_log'] / df['NumOfAtoms_sqrt']\n",
    "    df['Experimental11'] = df['NumHBondDonors'] / df['NumOfConf'] # addition to best2\n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\"../Data/train.csv\")\n",
    "test = pd.read_csv(\"../Data/test.csv\")\n",
    "\n",
    "# Preserve the ID column\n",
    "test_ids = test[\"ID\"]\n",
    "\n",
    "# Drop ID column from test data\n",
    "test.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "# Separate target variable from training data\n",
    "target = train[\"log_pSat_Pa\"]\n",
    "train.drop(columns=[\"log_pSat_Pa\", \"ID\"], inplace=True)\n",
    "\n",
    "# Apply feature engineering\n",
    "train_transformed = transform_features2(train.copy())\n",
    "test_transformed = transform_features2(test.copy())\n",
    "\n",
    "# One-hot encode categorical features \"parentspecies\" column\n",
    "train_transformed = pd.get_dummies(train_transformed, columns=[\"parentspecies\"], drop_first=True)\n",
    "test_transformed = pd.get_dummies(test_transformed, columns=[\"parentspecies\"], drop_first=True)\n",
    "\n",
    "# Align the columns of train and test data\n",
    "train_transformed, test_transformed = train_transformed.align(test_transformed, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Separate the parentspecies columns\n",
    "parentspecies_train = train_transformed.filter(like='parentspecies')\n",
    "parentspecies_test = test_transformed.filter(like='parentspecies')\n",
    "\n",
    "# Drop the parentspecies columns from the transformed data\n",
    "train_transformed = train_transformed.drop(columns=parentspecies_train.columns)\n",
    "test_transformed = test_transformed.drop(columns=parentspecies_test.columns)\n",
    "\n",
    "# Save the column names before scaling\n",
    "train_columns = train_transformed.columns\n",
    "test_columns = test_transformed.columns\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "train_transformed = scaler.fit_transform(train_transformed)\n",
    "test_transformed = scaler.transform(test_transformed)\n",
    "\n",
    "# Convert scaled numerical features back to DataFrame\n",
    "train_transformed = pd.DataFrame(train_transformed, columns=train_columns)\n",
    "test_transformed = pd.DataFrame(test_transformed, columns=test_columns)\n",
    "\n",
    "# Add the parentspecies columns back to the scaled numerical features\n",
    "train_transformed = pd.concat([train_transformed, parentspecies_train.reset_index(drop=True)], axis=1)\n",
    "test_transformed = pd.concat([test_transformed, parentspecies_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "best_params = {'n_estimators': 612, 'learning_rate': 0.03253420017567533, 'num_leaves': 123, 'max_depth': 7, 'min_child_samples': 46, 'subsample': 0.7456333280664998, 'colsample_bytree': 0.9137393037318097, 'reg_alpha': 0.7026860907781649, 'reg_lambda': 0.7187304208680759}\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "model.fit(train_transformed, target)\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = model.predict(train_transformed)\n",
    "rmse = mean_squared_error(target, train_predictions, squared=False)\n",
    "mae = mean_absolute_error(target, train_predictions)\n",
    "r2 = r2_score(target, train_predictions)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(test_transformed)\n",
    "output = pd.DataFrame({\"ID\": test_ids, \"TARGET\": test_predictions})\n",
    "output.to_csv(\"lgbm_best_cur.csv\", index=False)\n",
    "\n",
    "# view the feature importance\n",
    "importance = model.feature_importances_\n",
    "feature_names = train_transformed.columns\n",
    "feature_importance = pd.DataFrame({\"feature\": feature_names, \"importance\": importance})\n",
    "feature_importance = feature_importance.sort_values(by=\"importance\", ascending=False)\n",
    "print(feature_importance)\n",
    "\n",
    "# plot the feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance)\n",
    "plt.title(\"Feature Importance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
